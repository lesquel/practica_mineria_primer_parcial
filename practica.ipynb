{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06334fb",
   "metadata": {},
   "source": [
    "# Práctica de Minería de Datos: Evaluación de Calificaciones\n",
    "**Integrantes:** Nombre 1 · Nombre 2 (actualizar con los nombres completos)\n",
    "**Fecha:** 23 de octubre de 2025\n",
    "**Curso:** Minería de Datos - Proceso KDD con Clustering Jerárquico y K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4e31a",
   "metadata": {},
   "source": [
    "## Tabla de Contenidos\n",
    "1. Introducción\n",
    "2. Selección y Comprensión de Datos\n",
    "3. Preprocesamiento de Datos\n",
    "4. Exploración de Datos\n",
    "5. Modelado: Clustering Jerárquico\n",
    "6. Modelado: K-Means\n",
    "7. Evaluación y Comparación\n",
    "8. Sensibilidad de Parámetros y Métricas Adicionales\n",
    "9. Conclusiones y Recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d091fc63",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "En esta práctica aplicamos el proceso KDD para analizar el desempeño académico de un conjunto de estudiantes. Los objetivos principales son:\n",
    "- depurar y transformar los datos para garantizar su calidad;\n",
    "- explorar las variables y su comportamiento;\n",
    "- generar agrupaciones con algoritmos de clustering jerárquico y K-Means;\n",
    "- evaluar y comparar ambos enfoques mediante métricas cuantitativas y visualizaciones;\n",
    "- interpretar los clusters para proponer recomendaciones accionables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1453617",
   "metadata": {},
   "source": [
    "## 2. Selección y Comprensión de Datos\n",
    "Trabajamos con el archivo `notas-Estudiantes.csv`, que recopila las calificaciones de 15 estudiantes en cinco asignaturas: Matemáticas, Ciencias, Español, Historia y Deportes. El dataset proviene de un registro interno del curso y presenta varios problemas de calidad (valores faltantes, caracteres no numéricos, puntuaciones negativas, duplicados y magnitudes fuera de rango) que justifican una fase de limpieza rigurosa.\n",
    "A continuación se describen las variables incluidas:\n",
    "- **Nombre:** identificador único del estudiante.\n",
    "- **Matemáticas, Ciencias, Español, Historia, Deportes:** calificaciones numéricas esperadas en la escala de 0 a 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías principales para el proceso KDD y los algoritmos de clustering\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.manifold import TSNE\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fdedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset original\n",
    "DATA_PATH = Path(\"notas-Estudiantes.csv\")\n",
    "raw_df = pd.read_csv(DATA_PATH)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2fde10",
   "metadata": {},
   "source": [
    "### 2.1 Análisis exploratorio inicial\n",
    "Evaluamos estructura, tipos de datos, conteo de nulos y observaciones preliminares para cumplir con la rúbrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5bdea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos estructura, tipos de datos y valores faltantes declarados\n",
    "raw_summary = {\n",
    "    \"Filas\": raw_df.shape[0],\n",
    "    \"Columnas\": raw_df.shape[1],\n",
    "    \"Tipos\": raw_df.dtypes.astype(str).to_dict(),\n",
    "    \"Nulos_reportados\": raw_df.isna().sum().to_dict()\n",
    "}\n",
    "\n",
    "raw_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f049459",
   "metadata": {},
   "source": [
    "Observamos que las columnas académicas son importadas como objeto porque existen caracteres no numéricos (por ejemplo `7.3i`, `NA`, `null`). Además, existen valores fuera del rango esperado 0-10 y filas duplicadas. Procedemos a documentar y corregir estas incidencias en la sección de preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c0a2f",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento de Datos\n",
    "Aplicamos un pipeline reproducible que estandariza las calificaciones, maneja valores faltantes, corrige registros inválidos y elimina duplicados. Además de mejorar la calidad, generamos un informe de control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266becdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline encapsulado para limpiar y validar las calificaciones\n",
    "class GradeCleaningPipeline:\n",
    "    def __init__(self, value_cols, valid_range=(0, 10)):\n",
    "        self.value_cols = value_cols\n",
    "        self.valid_min, self.valid_max = valid_range\n",
    "        self.medians_ = None\n",
    "        self.quality_report_ = {}\n",
    "    \n",
    "    def _coerce_numeric(self, df):\n",
    "        converted = df.copy()\n",
    "        coercion_issues = {}\n",
    "        for col in self.value_cols:\n",
    "            before_invalid = converted[col].isna().sum()\n",
    "            converted[col] = pd.to_numeric(converted[col], errors=\"coerce\")\n",
    "            after_invalid = converted[col].isna().sum()\n",
    "            coercion_issues[col] = after_invalid - before_invalid\n",
    "        return converted, coercion_issues\n",
    "    \n",
    "    def _flag_out_of_range(self, df):\n",
    "        mask_low = df[self.value_cols] < self.valid_min\n",
    "        mask_high = df[self.value_cols] > self.valid_max\n",
    "        out_of_range = (mask_low | mask_high).sum().to_dict()\n",
    "        df[self.value_cols] = df[self.value_cols].mask(mask_low | mask_high)\n",
    "        return df, out_of_range\n",
    "    \n",
    "    def _impute(self, df):\n",
    "        self.medians_ = df[self.value_cols].median()\n",
    "        return df.assign(**{col: df[col].fillna(self.medians_[col]) for col in self.value_cols})\n",
    "    \n",
    "    def fit_transform(self, df):\n",
    "        working = df.copy()\n",
    "        quality = {}\n",
    "        working, coercion = self._coerce_numeric(working)\n",
    "        quality[\"no_convertibles\"] = coercion\n",
    "        duplicates = working.duplicated().sum()\n",
    "        working = working.drop_duplicates()\n",
    "        quality[\"duplicados_eliminados\"] = int(duplicates)\n",
    "        working, out_of_range = self._flag_out_of_range(working)\n",
    "        quality[\"fuera_de_rango\"] = out_of_range\n",
    "        quality[\"nulos_post_rango\"] = working[self.value_cols].isna().sum().to_dict()\n",
    "        working = self._impute(working)\n",
    "        quality[\"imputacion_mediana\"] = self.medians_.to_dict()\n",
    "        quality[\"nulos_finales\"] = working[self.value_cols].isna().sum().to_dict()\n",
    "        self.quality_report_ = quality\n",
    "        return working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos el pipeline y guardamos el reporte de calidad\n",
    "value_cols = [\"Matematicas\", \"Ciencias\", \"Espanol\", \"Historia\", \"Deportes\"]\n",
    "cleaner = GradeCleaningPipeline(value_cols=value_cols)\n",
    "clean_df = cleaner.fit_transform(raw_df)\n",
    "quality_report = cleaner.quality_report_\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045347f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estructurado de incidencias detectadas y acciones correctivas\n",
    "quality_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8eb92c",
   "metadata": {},
   "source": [
    "El pipeline identifica datos no convertibles (literales con letras), valores fuera de rango y duplicados exactos. Al usar la mediana por asignatura eliminamos los `NaN` residuales sin distorsionar la escala 0-10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cda46e",
   "metadata": {},
   "source": [
    "## 4. Exploración de Datos\n",
    "Realizamos estadísticas descriptivas, distribuciones y correlaciones sobre el dataset limpio para comprender patrones previos al modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas del dataset limpio\n",
    "clean_df[value_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuciones e identificación visual de asimetrías\n",
    "fig, axes = plt.subplots(2, len(value_cols), figsize=(18, 8))\n",
    "for idx, col in enumerate(value_cols):\n",
    "    sns.histplot(clean_df[col], kde=True, ax=axes[0, idx], color=\"#4c72b0\")\n",
    "    axes[0, idx].set_title(f\"Histograma {col}\")\n",
    "    sns.boxplot(x=clean_df[col], ax=axes[1, idx], color=\"#dd8452\")\n",
    "    axes[1, idx].set_title(f\"Boxplot {col}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c4b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación entre asignaturas\n",
    "corr_matrix = clean_df[value_cols].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"YlGnBu\", vmin=0, vmax=1)\n",
    "plt.title(\"Correlación de calificaciones\")\n",
    "plt.show()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baec7de",
   "metadata": {},
   "source": [
    "**Hallazgos clave del EDA:**\n",
    "- Mayor dispersión en Historia y Matemáticas; Deportes muestra menor variabilidad tras la imputación.\n",
    "- Las materias teóricas presentan correlaciones altas (≥0.7), lo que justifica usar reducción de dimensionalidad antes de clusterizar para evitar colinealidad.\n",
    "- Persisten diferencias entre estudiantes con perfiles equilibrados y otros con fortalezas puntuales, lo que esperamos capturar en los clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizamos las calificaciones para evitar sesgos por escala\n",
    "scaler = StandardScaler()\n",
    "scaled_array = scaler.fit_transform(clean_df[value_cols])\n",
    "scaled_df = pd.DataFrame(scaled_array, columns=value_cols, index=clean_df.index)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA para condensar la información en dos componentes interpretables\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_components = pca.fit_transform(scaled_df)\n",
    "pca_df = pd.DataFrame(pca_components, columns=[\"PC1\", \"PC2\"], index=clean_df.index)\n",
    "explained_variance = pd.Series(pca.explained_variance_ratio_, index=[\"PC1\", \"PC2\"])\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38620b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargas de las componentes principales para interpretación\n",
    "loadings = pd.DataFrame(pca.components_.T, index=value_cols, columns=[\"PC1\", \"PC2\"])\n",
    "loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85612513",
   "metadata": {},
   "source": [
    "La varianza acumulada de las dos primeras componentes supera el 80 %, lo que permite proyectar en 2D sin perder información crítica. `PC1` concentra el rendimiento general (cargas positivas similares) y `PC2` diferencia materias físicas/deportivas de las humanísticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e45994",
   "metadata": {},
   "source": [
    "## 5. Modelado: Clustering Jerárquico\n",
    "Implementamos clustering aglomerativo con distancia euclidiana y enlace `ward`, apoyado en un dendrograma y métricas cuantitativas (Silhouette, Davies-Bouldin, Calinski-Harabasz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1acb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dendrograma para visualizar la estructura jerárquica\n",
    "linkage_matrix = linkage(scaled_df, method=\"ward\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram(linkage_matrix, labels=clean_df[\"Nombre\"].values, leaf_rotation=45)\n",
    "plt.title(\"Dendrograma - Enlace Ward\")\n",
    "plt.ylabel(\"Distancia\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
