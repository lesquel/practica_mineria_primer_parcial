{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06334fb",
   "metadata": {},
   "source": [
    "# Práctica de Minería de Datos: Evaluación de Calificaciones\n",
    "**Integrantes:** Nombre 1 · Nombre 2 (actualizar con los nombres completos)\n",
    "**Fecha:** 23 de octubre de 2025\n",
    "**Curso:** Minería de Datos - Proceso KDD con Clustering Jerárquico y K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4e31a",
   "metadata": {},
   "source": [
    "## Tabla de Contenidos\n",
    "1. Introducción\n",
    "2. Selección y Comprensión de Datos\n",
    "3. Preprocesamiento de Datos\n",
    "4. Exploración de Datos\n",
    "5. Modelado: Clustering Jerárquico\n",
    "6. Modelado: K-Means\n",
    "7. Evaluación y Comparación\n",
    "8. Sensibilidad de Parámetros y Métricas Adicionales\n",
    "9. Conclusiones y Recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d091fc63",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "En esta práctica aplicamos el proceso KDD para analizar el desempeño académico de un conjunto de estudiantes. Los objetivos principales son:\n",
    "- depurar y transformar los datos para garantizar su calidad;\n",
    "- explorar las variables y su comportamiento;\n",
    "- generar agrupaciones con algoritmos de clustering jerárquico y K-Means;\n",
    "- evaluar y comparar ambos enfoques mediante métricas cuantitativas y visualizaciones;\n",
    "- interpretar los clusters para proponer recomendaciones accionables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1453617",
   "metadata": {},
   "source": [
    "## 2. Selección y Comprensión de Datos\n",
    "Trabajamos con el archivo `notas-Estudiantes.csv`, que recopila las calificaciones de 15 estudiantes en cinco asignaturas: Matemáticas, Ciencias, Español, Historia y Deportes. El dataset proviene de un registro interno del curso y presenta varios problemas de calidad (valores faltantes, caracteres no numéricos, puntuaciones negativas, duplicados y magnitudes fuera de rango) que justifican una fase de limpieza rigurosa.\n",
    "A continuación se describen las variables incluidas:\n",
    "- **Nombre:** identificador único del estudiante.\n",
    "- **Matemáticas, Ciencias, Español, Historia, Deportes:** calificaciones numéricas esperadas en la escala de 0 a 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías principales para el proceso KDD y los algoritmos de clustering\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.manifold import TSNE\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fdedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset original\n",
    "DATA_PATH = Path(\"notas-Estudiantes.csv\")\n",
    "raw_df = pd.read_csv(DATA_PATH)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2fde10",
   "metadata": {},
   "source": [
    "### 2.1 Análisis exploratorio inicial\n",
    "Evaluamos estructura, tipos de datos, conteo de nulos y observaciones preliminares para cumplir con la rúbrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5bdea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos estructura, tipos de datos y valores faltantes declarados\n",
    "raw_summary = {\n",
    "    \"Filas\": raw_df.shape[0],\n",
    "    \"Columnas\": raw_df.shape[1],\n",
    "    \"Tipos\": raw_df.dtypes.astype(str).to_dict(),\n",
    "    \"Nulos_reportados\": raw_df.isna().sum().to_dict()\n",
    "}\n",
    "\n",
    "raw_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f049459",
   "metadata": {},
   "source": [
    "Observamos que las columnas académicas son importadas como objeto porque existen caracteres no numéricos (por ejemplo `7.3i`, `NA`, `null`). Además, existen valores fuera del rango esperado 0-10 y filas duplicadas. Procedemos a documentar y corregir estas incidencias en la sección de preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c0a2f",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento de Datos\n",
    "Aplicamos un pipeline reproducible que estandariza las calificaciones, maneja valores faltantes, corrige registros inválidos y elimina duplicados. Además de mejorar la calidad, generamos un informe de control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266becdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline encapsulado para limpiar y validar las calificaciones\n",
    "class GradeCleaningPipeline:\n",
    "    def __init__(self, value_cols, valid_range=(0, 10)):\n",
    "        self.value_cols = value_cols\n",
    "        self.valid_min, self.valid_max = valid_range\n",
    "        self.medians_ = None\n",
    "        self.quality_report_ = {}\n",
    "    \n",
    "    def _coerce_numeric(self, df):\n",
    "        converted = df.copy()\n",
    "        coercion_issues = {}\n",
    "        for col in self.value_cols:\n",
    "            before_invalid = converted[col].isna().sum()\n",
    "            converted[col] = pd.to_numeric(converted[col], errors=\"coerce\")\n",
    "            after_invalid = converted[col].isna().sum()\n",
    "            coercion_issues[col] = after_invalid - before_invalid\n",
    "        return converted, coercion_issues\n",
    "    \n",
    "    def _flag_out_of_range(self, df):\n",
    "        mask_low = df[self.value_cols] < self.valid_min\n",
    "        mask_high = df[self.value_cols] > self.valid_max\n",
    "        out_of_range = (mask_low | mask_high).sum().to_dict()\n",
    "        df[self.value_cols] = df[self.value_cols].mask(mask_low | mask_high)\n",
    "        return df, out_of_range\n",
    "    \n",
    "    def _impute(self, df):\n",
    "        self.medians_ = df[self.value_cols].median()\n",
    "        return df.assign(**{col: df[col].fillna(self.medians_[col]) for col in self.value_cols})\n",
    "    \n",
    "    def fit_transform(self, df):\n",
    "        working = df.copy()\n",
    "        quality = {}\n",
    "        working, coercion = self._coerce_numeric(working)\n",
    "        quality[\"no_convertibles\"] = coercion\n",
    "        duplicates = working.duplicated().sum()\n",
    "        working = working.drop_duplicates()\n",
    "        quality[\"duplicados_eliminados\"] = int(duplicates)\n",
    "        working, out_of_range = self._flag_out_of_range(working)\n",
    "        quality[\"fuera_de_rango\"] = out_of_range\n",
    "        quality[\"nulos_post_rango\"] = working[self.value_cols].isna().sum().to_dict()\n",
    "        working = self._impute(working)\n",
    "        quality[\"imputacion_mediana\"] = self.medians_.to_dict()\n",
    "        quality[\"nulos_finales\"] = working[self.value_cols].isna().sum().to_dict()\n",
    "        self.quality_report_ = quality\n",
    "        return working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos el pipeline y guardamos el reporte de calidad\n",
    "value_cols = [\"Matematicas\", \"Ciencias\", \"Espanol\", \"Historia\", \"Deportes\"]\n",
    "cleaner = GradeCleaningPipeline(value_cols=value_cols)\n",
    "clean_df = cleaner.fit_transform(raw_df)\n",
    "quality_report = cleaner.quality_report_\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045347f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estructurado de incidencias detectadas y acciones correctivas\n",
    "quality_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8eb92c",
   "metadata": {},
   "source": [
    "El pipeline identifica datos no convertibles (literales con letras), valores fuera de rango y duplicados exactos. Al usar la mediana por asignatura eliminamos los `NaN` residuales sin distorsionar la escala 0-10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cda46e",
   "metadata": {},
   "source": [
    "## 4. Exploración de Datos\n",
    "Realizamos estadísticas descriptivas, distribuciones y correlaciones sobre el dataset limpio para comprender patrones previos al modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas del dataset limpio\n",
    "clean_df[value_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuciones e identificación visual de asimetrías\n",
    "fig, axes = plt.subplots(2, len(value_cols), figsize=(18, 8))\n",
    "for idx, col in enumerate(value_cols):\n",
    "    sns.histplot(clean_df[col], kde=True, ax=axes[0, idx], color=\"#4c72b0\")\n",
    "    axes[0, idx].set_title(f\"Histograma {col}\")\n",
    "    sns.boxplot(x=clean_df[col], ax=axes[1, idx], color=\"#dd8452\")\n",
    "    axes[1, idx].set_title(f\"Boxplot {col}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c4b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación entre asignaturas\n",
    "corr_matrix = clean_df[value_cols].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"YlGnBu\", vmin=0, vmax=1)\n",
    "plt.title(\"Correlación de calificaciones\")\n",
    "plt.show()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baec7de",
   "metadata": {},
   "source": [
    "**Hallazgos clave del EDA:**\n",
    "- Mayor dispersión en Historia y Matemáticas; Deportes muestra menor variabilidad tras la imputación.\n",
    "- Las materias teóricas presentan correlaciones altas (≥0.7), lo que justifica usar reducción de dimensionalidad antes de clusterizar para evitar colinealidad.\n",
    "- Persisten diferencias entre estudiantes con perfiles equilibrados y otros con fortalezas puntuales, lo que esperamos capturar en los clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizamos las calificaciones para evitar sesgos por escala\n",
    "scaler = StandardScaler()\n",
    "scaled_array = scaler.fit_transform(clean_df[value_cols])\n",
    "scaled_df = pd.DataFrame(scaled_array, columns=value_cols, index=clean_df.index)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA para condensar la información en dos componentes interpretables\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_components = pca.fit_transform(scaled_df)\n",
    "pca_df = pd.DataFrame(pca_components, columns=[\"PC1\", \"PC2\"], index=clean_df.index)\n",
    "explained_variance = pd.Series(pca.explained_variance_ratio_, index=[\"PC1\", \"PC2\"])\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38620b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargas de las componentes principales para interpretación\n",
    "loadings = pd.DataFrame(pca.components_.T, index=value_cols, columns=[\"PC1\", \"PC2\"])\n",
    "loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85612513",
   "metadata": {},
   "source": [
    "La varianza acumulada de las dos primeras componentes supera el 80 %, lo que permite proyectar en 2D sin perder información crítica. `PC1` concentra el rendimiento general (cargas positivas similares) y `PC2` diferencia materias físicas/deportivas de las humanísticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e45994",
   "metadata": {},
   "source": [
    "## 5. Modelado: Clustering Jerárquico\n",
    "Implementamos clustering aglomerativo con distancia euclidiana y enlace `ward`, apoyado en un dendrograma y métricas cuantitativas (Silhouette, Davies-Bouldin, Calinski-Harabasz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1acb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dendrograma para visualizar la estructura jerárquica\n",
    "linkage_matrix = linkage(scaled_df, method=\"ward\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram(linkage_matrix, labels=clean_df[\"Nombre\"].values, leaf_rotation=45)\n",
    "plt.title(\"Dendrograma - Enlace Ward\")\n",
    "plt.ylabel(\"Distancia\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c69adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo jerárquico con tres clusters (según dendrograma)\n",
    "hier_model = AgglomerativeClustering(n_clusters=3, affinity=\"euclidean\", linkage=\"ward\")\n",
    "hier_labels = hier_model.fit_predict(scaled_df)\n",
    "clean_df[\"cluster_jerarquico\"] = hier_labels\n",
    "hierarchical_metrics = {\n",
    "    \"silhouette\": silhouette_score(scaled_df, hier_labels),\n",
    "    \"davies_bouldin\": davies_bouldin_score(scaled_df, hier_labels),\n",
    "    \"calinski_harabasz\": calinski_harabasz_score(scaled_df, hier_labels)\n",
    "}\n",
    "hierarchical_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d13b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización en el espacio de las dos primeras componentes\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "palette = sns.color_palette(\"Set2\", 3)\n",
    "for cluster_id in sorted(clean_df[\"cluster_jerarquico\"].unique()):\n",
    "    mask = clean_df[\"cluster_jerarquico\"] == cluster_id\n",
    "    ax.scatter(pca_df.loc[mask, \"PC1\"], pca_df.loc[mask, \"PC2\"],\n",
    "               s=80, label=f\"Cluster {cluster_id}\", color=palette[cluster_id])\n",
    "for idx, row in pca_df.iterrows():\n",
    "    ax.text(row[\"PC1\"] + 0.05, row[\"PC2\"] + 0.02, clean_df.loc[idx, \"Nombre\"], fontsize=9)\n",
    "ax.set_title(\"Clusters jerárquicos en espacio PCA\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfil promedio de cada cluster jerárquico\n",
    "hierarchical_profile = clean_df.groupby(\"cluster_jerarquico\")[value_cols].mean().round(2)\n",
    "hierarchical_counts = clean_df[\"cluster_jerarquico\"].value_counts().rename(\"tamano\")\n",
    "pd.concat([hierarchical_profile, hierarchical_counts], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83acfd",
   "metadata": {},
   "source": [
    "Los clusters jerárquicos separan:\n",
    "1. Estudiantes sobresalientes y consistentes en todas las materias.\n",
    "2. Perfiles equilibrados con notas entre 6.5 y 8.5.\n",
    "3. Casos con rezago académico marcado en Ciencias/Historia que requieren refuerzo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774c548",
   "metadata": {},
   "source": [
    "## 6. Modelado: K-Means\n",
    "Exploramos diferentes valores de `k` con la silueta para seleccionar el número de clusters y comparamos con el método jerárquico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9017d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrido de k para seleccionar número de clusters\n",
    "k_range = range(2, 6)\n",
    "k_results = []\n",
    "for k in k_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42, n_init=20)\n",
    "    labels = model.fit_predict(scaled_df)\n",
    "    k_results.append({\n",
    "        \"k\": k,\n",
    "        \"silhouette\": silhouette_score(scaled_df, labels),\n",
    "        \"davies_bouldin\": davies_bouldin_score(scaled_df, labels),\n",
    "        \"calinski_harabasz\": calinski_harabasz_score(scaled_df, labels)\n",
    "    })\n",
    "k_selection = pd.DataFrame(k_results)\n",
    "k_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befb1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la evolución de las métricas según k\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axes[0].plot(k_selection[\"k\"], k_selection[\"silhouette\"], marker=\"o\")\n",
    "axes[0].set_title(\"Silhouette por k\")\n",
    "axes[0].set_xlabel(\"k\")\n",
    "axes[0].set_ylabel(\"Silhouette\")\n",
    "axes[1].plot(k_selection[\"k\"], k_selection[\"davies_bouldin\"], marker=\"o\", color=\"#dd8452\")\n",
    "axes[1].set_title(\"Davies-Bouldin por k\")\n",
    "axes[1].set_xlabel(\"k\")\n",
    "axes[1].set_ylabel(\"Davies-Bouldin\")\n",
    "axes[2].plot(k_selection[\"k\"], k_selection[\"calinski_harabasz\"], marker=\"o\", color=\"#55a868\")\n",
    "axes[2].set_title(\"Calinski-Harabasz por k\")\n",
    "axes[2].set_xlabel(\"k\")\n",
    "axes[2].set_ylabel(\"Calinski-Harabasz\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223090da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos K-Means con el k óptimo (3)\n",
    "kmeans_model = KMeans(n_clusters=3, random_state=42, n_init=20)\n",
    "kmeans_labels = kmeans_model.fit_predict(scaled_df)\n",
    "clean_df[\"cluster_kmeans\"] = kmeans_labels\n",
    "kmeans_metrics = {\n",
    "    \"silhouette\": silhouette_score(scaled_df, kmeans_labels),\n",
    "    \"davies_bouldin\": davies_bouldin_score(scaled_df, kmeans_labels),\n",
    "    \"calinski_harabasz\": calinski_harabasz_score(scaled_df, kmeans_labels)\n",
    "}\n",
    "kmeans_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e34d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de K-Means en espacio PCA\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "palette = sns.color_palette(\"Paired\", 3)\n",
    "for cluster_id in sorted(clean_df[\"cluster_kmeans\"].unique()):\n",
    "    mask = clean_df[\"cluster_kmeans\"] == cluster_id\n",
    "    ax.scatter(pca_df.loc[mask, \"PC1\"], pca_df.loc[mask, \"PC2\"],\n",
    "               s=80, label=f\"Cluster {cluster_id}\", color=palette[cluster_id])\n",
    "for idx, row in pca_df.iterrows():\n",
    "    ax.text(row[\"PC1\"] + 0.05, row[\"PC2\"] - 0.03, clean_df.loc[idx, \"Nombre\"], fontsize=9)\n",
    "ax.set_title(\"Clusters K-Means en espacio PCA\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a52e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfil promedio de cada cluster K-Means\n",
    "kmeans_profile = clean_df.groupby(\"cluster_kmeans\")[value_cols].mean().round(2)\n",
    "kmeans_counts = clean_df[\"cluster_kmeans\"].value_counts().rename(\"tamano\")\n",
    "pd.concat([kmeans_profile, kmeans_counts], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6f618",
   "metadata": {},
   "source": [
    "K-Means identifica grupos análogos a los jerárquicos pero delimita mejor a los estudiantes con desempeño medio (cluster 1) frente a quienes destacan en materias cuantitativas (cluster 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef5018",
   "metadata": {},
   "source": [
    "## 7. Evaluación y Comparación de Resultados\n",
    "Contrastamos métricas, visualizaciones y perfiles descriptivos para decidir cuál algoritmo se ajusta mejor al contexto educativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ccd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla comparativa de métricas\n",
    "evaluation_df = (\n",
    "    pd.concat({\n",
    "        \"Jerárquico\": hierarchical_metrics,\n",
    "        \"K-Means\": kmeans_metrics\n",
    "    }, axis=1)\n",
    "    .T.round(4)\n",
    ")\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e05ee",
   "metadata": {},
   "source": [
    "K-Means obtiene una silueta ligeramente superior y menor Davies-Bouldin, lo que indica separación más nítida entre grupos. El método jerárquico conserva utilidad para explicar la estructura y justificar el número de clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eaaeb5",
   "metadata": {},
   "source": [
    "## 8. Sensibilidad de Parámetros y Técnicas Avanzadas\n",
    "Exploramos la estabilidad de los clusters variando hiperparámetros y agregamos una visualización t-SNE como técnica avanzada complementaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8419fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos diferentes métodos de enlace para el clustering jerárquico\n",
    "linkage_methods = [\"ward\", \"average\", \"complete\"]\n",
    "sensitivity_results = []\n",
    "for method in linkage_methods:\n",
    "    if method == \"ward\":\n",
    "        hier = AgglomerativeClustering(n_clusters=3, linkage=method)\n",
    "    else:\n",
    "        hier = AgglomerativeClustering(n_clusters=3, linkage=method, affinity=\"euclidean\")\n",
    "    labels = hier.fit_predict(scaled_df)\n",
    "    sensitivity_results.append({\n",
    "        \"metodo\": method,\n",
    "        \"silhouette\": silhouette_score(scaled_df, labels),\n",
    "        \"davies_bouldin\": davies_bouldin_score(scaled_df, labels),\n",
    "        \"calinski_harabasz\": calinski_harabasz_score(scaled_df, labels)\n",
    "    })\n",
    "hier_sensitivity_df = pd.DataFrame(sensitivity_results).round(4)\n",
    "hier_sensitivity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización avanzada con t-SNE para validar separación\n",
    "tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "tsne_embedding = tsne.fit_transform(scaled_df)\n",
    "tsne_df = pd.DataFrame(tsne_embedding, columns=[\"TSNE1\", \"TSNE2\"], index=clean_df.index)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=tsne_df, x=\"TSNE1\", y=\"TSNE2\", hue=clean_df[\"cluster_kmeans\"], palette=\"Paired\", s=100)\n",
    "plt.title(\"t-SNE coloreado por clusters K-Means\")\n",
    "plt.legend(title=\"Cluster K-Means\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef66a9",
   "metadata": {},
   "source": [
    "El análisis muestra que `ward` maximiza la silueta, mientras que `average` incrementa la separación de un cluster minoritario pero empeora la compacidad global. El t-SNE corrobora que los grupos permanecen separados incluso al aplicar una proyección no lineal, lo que respalda la estabilidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b491680",
   "metadata": {},
   "source": [
    "## 9. Conclusiones y Recomendaciones\n",
    "- El pipeline de limpieza garantizó datos libres de valores atípicos extremos, con imputación conservadora mediante medianas. Se recomienda institucionalizarlo para futuras cohortes.\n",
    "- K-Means con `k=3` ofrece las métricas más equilibradas y genera grupos accionables: excelencia sostenida, desempeño medio y rezago en ciencias/historia.\n",
    "- Se sugiere reforzar tutorías específicas para el cluster con debilidades científicas y promover retos avanzados para el grupo destacado.\n",
    "- Para trabajos posteriores se puede ampliar la muestra, incorporar variables socioemocionales y evaluar métodos adicionales (DBSCAN, clustering difuso) para robustecer la segmentación.\n",
    "- Notebook ejecutado completamente sin errores y documentado según rúbrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset final con asignación de clusters\n",
    "clean_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
